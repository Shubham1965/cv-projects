{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e26635a1631410653714a9c61f37d523",
     "grade": false,
     "grade_id": "cell-3f7c04052f69174a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mean-Shift Clustering and Segmentation\n",
    "\n",
    "In the first part of this task you will implement the *mean-shift* clustering algorithm in a general way (not specifically for anything to do with images, just simply for n-dimensional data points).\n",
    "\n",
    "Then in the second part you will apply mean-shift for image segmentation, by clustering data points that represent pixels (e.g. the colors).\n",
    "\n",
    "### Recap from the lecture\n",
    "The *mean-shift* algorithm clusters an $n$-dimensional data set (i.e., each data point is described by a feature vector of $n$ values) by associating each point with a peak in the estimated probability density of the dataset's distribution. Points associated with the \"same\" peak (up to some small threshold) become members of the same cluster.\n",
    "\n",
    "For each point, mean-shift finds the associated peak by first defining a spherical window of radius $r$ centered on that point, and computing the **mean** of the points that lie within the window. The algorithm then **shifts** the window to be centered on that mean and repeats these steps until convergence, i.e., until the shift is smaller than a specified threshold. At each iteration the window shifts to a more densely populated portion of the data set until a peak is reached, where the data is approximately equally distributed in the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1dca7b7d3487ec5eadafa7c75d41dc0",
     "grade": false,
     "grade_id": "cell-07c7571d66aaa705",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<!-- Run this cell to add heading letters per subtask (like a, b, c) -->\n",
    "<style>\n",
    "body {counter-reset: section;}\n",
    "h2:before {counter-increment: section;\n",
    "           content: counter(section, lower-alpha) \") \";}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cea01a7337fe044a7dabeb8160ddaa4",
     "grade": false,
     "grade_id": "cell-3ed65422382d86ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import imageio\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e9ba81b4785ef8b3b53a1527488e045",
     "grade": false,
     "grade_id": "cell-f4614aa28ba2543e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "\n",
    "## Finding a peak from a query point\n",
    "Implement the peak searching process as the function `find_peak(data, query, radius)` where\n",
    "\n",
    " * `data` is a $p \\times n$ matrix containing $p$ data points; each point is defined by an $n$-dimensional row vector of feature values\n",
    " * `query` is the $n$-dimensional starting point from which we wish to compute a density peak\n",
    " * `radius` is the search window radius.\n",
    "\n",
    "Return the peak as an $n$-dimensional vector.\n",
    "\n",
    "**Hints:** You can use `np.linalg.norm` to compute the Euclidean norm of a vector. You can also index NumPy arrays with Boolean arrays, e.g. to select only rows that fulfil some criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3f10c3f20de478dc68f3334a1e55d1",
     "grade": true,
     "grade_id": "cell-456db7ce2d4ca848",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 2\n",
    "\n",
    "def find_peak(data, query, radius):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9f5267b34fdcf194a2cb5e48a56e908",
     "grade": false,
     "grade_id": "cell-62db40e59125552e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will now use the synthetic dataset `gaussian_mixture_samples_3d.csv` to test your implementation. The data points in this file are 2000 samples from two 3D Gaussian distributions. The following plots only show the projection on the XY plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "191b4dc24ec2266b4e6251df2933bf13",
     "grade": false,
     "grade_id": "cell-985a50560171c45b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(f'gaussian_mixture_samples_3d.csv', delimiter=',')\n",
    "query_ids = [0, 5, 1500]\n",
    "radius = 2\n",
    "\n",
    "fig, axes = plt.subplots(1, len(query_ids), figsize=(9.5,3.5))\n",
    "for query_id, ax in zip(query_ids, axes):\n",
    "    query = data[query_id]\n",
    "    peak = find_peak(data, query, radius)\n",
    "    print('Found peak', peak)\n",
    "    \n",
    "    ax.scatter(data[:, 0], data[:, 1], marker='.', color='gray')\n",
    "    ax.scatter(query[0], query[1], s=150, linewidth=5,\n",
    "               color='blue', marker='x', label='starting point')\n",
    "    ax.scatter(peak[0], peak[1], color='orange', marker='x',\n",
    "               s=150, linewidth=5, label='found peak')\n",
    "    ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dc76c8907602451086db3955af467d1",
     "grade": false,
     "grade_id": "cell-562f50edf3be564e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Clustering all points\n",
    "Implement `mean_shift(data, radius)`, which calls `find_peak` for each point and then assigns a label to each point according to its peak.\n",
    "`mean_shift` should return two arrays: `peaks` and `labels`.\n",
    "\n",
    "  * `peaks` is a matrix with $k$ rows, storing the found density peaks, where $k$ is the data-dependent number of clusters found. \n",
    "  * `labels` is a $p$-sized vector that has an entry for each data point, storing its associated cluster label (an integer)\n",
    "\n",
    "Similar peaks within a distance of `radius/2` should be considered the same and should be merged after each call to `find_peak`. More specifically, if the peak computed for a data point already exists in `peaks` (according to the distance threshold), then discard the newly computed peak and give the label of the already existing peak to the considered data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "826793849248c5a541976a50040d7a52",
     "grade": true,
     "grade_id": "cell-350b0f2a0fb1876f",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 4\n",
    "\n",
    "def mean_shift(data, radius):\n",
    "    labels = np.full(len(data), fill_value=-1, dtype=int)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return peaks, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddd69a92c6c53d83e3e121e2923bca6e",
     "grade": false,
     "grade_id": "cell-89fb7fd3b16d054b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now check the result of your implementation. The found peaks (cluster centers) are shown as black X marks. You can rotate the interactive 3D plots with the mouse (but it may be somewhat slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e27b05f8c97d237c389c1583b908d9d1",
     "grade": false,
     "grade_id": "cell-c7c237e3da0e6ce8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_3d_clusters(ax, data, labels, peaks, \n",
    "                     peak_colors=None, colors=None, axis_names='xyz'):\n",
    "    \"\"\"Plots a set of point clusters in 3D, each with different color.\"\"\"\n",
    "\n",
    "    def luv2rgb(color):\n",
    "        expanded = color[np.newaxis, np.newaxis]\n",
    "        rgb = cv2.cvtColor(expanded.astype(np.uint8), cv2.COLOR_LUV2RGB)\n",
    "        return rgb[0,0]/255\n",
    "      \n",
    "    if peak_colors is None:\n",
    "        peak_colors = peaks\n",
    "    \n",
    "    for label in range(len(peaks)):\n",
    "        if colors=='rgb':\n",
    "            cluster_color = color = peak_colors[label]/255\n",
    "        elif colors=='luv':\n",
    "            cluster_color = luv2rgb(peak_colors[label])\n",
    "        else:\n",
    "            cluster_color=None\n",
    "\n",
    "        cluster = data[labels==label]\n",
    "        ax.scatter(cluster[:, 0], cluster[:, 1], cluster[:, 2],\n",
    "                   alpha=0.15, color=cluster_color)\n",
    "        ax.scatter(peaks[label, 0], peaks[label, 1], peaks[label, 2], \n",
    "                   color='black', marker='x', s=150, linewidth=3)\n",
    "\n",
    "    ax.set_xlabel(axis_names[0])\n",
    "    ax.set_ylabel(axis_names[1])\n",
    "    ax.set_zlabel(axis_names[2])\n",
    "\n",
    "data = np.genfromtxt(f'gaussian_mixture_samples_3d.csv', delimiter=',')\n",
    "radii = [1, 1.25, 2, 8]\n",
    "fig, axes = plt.subplots(\n",
    "    1, len(radii), figsize=(15,4), subplot_kw={'projection': '3d'})\n",
    "\n",
    "for radius, ax in zip(radii, axes): \n",
    "    start_time = time.time()\n",
    "    peaks, labels = mean_shift(data, radius)\n",
    "    plot_3d_clusters(ax, data, labels, peaks)\n",
    "    duration = time.time()-start_time\n",
    "    ax.set_title(\n",
    "        f'Found {len(peaks)} peaks using radius={radius:.2f}\\n'\n",
    "        f'Computation took {duration:.4f} s\\n')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "044d1fc2bd841837cbe7a5af38abfaff",
     "grade": false,
     "grade_id": "cell-4316ac09660beb91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Speedups\n",
    "\n",
    "As described so far, the mean-shift algorithm is too slow to be used for image segmentation where each data point corresponds to a pixel, there are just too many pixels in normal sized images. Therefore, you should incorporate the following two speedups from the lecture into your implementation. \n",
    "\n",
    "**First speedup**: upon finding a new peak, associate each data point within `radius` distance from that peak with the cluster defined by that peak. This speedup is known as the *“basin of attraction”* and is based on the intuition that points within one window size distance from the peak will, with high probability, converge to that peak.\n",
    "\n",
    "Call the new function `mean_shift_opt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76c5559f2fdfb91bea417ab1bcf692a0",
     "grade": true,
     "grade_id": "cell-f0792525823c53d4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def mean_shift_opt(data, radius):\n",
    "    labels = np.full(len(data), fill_value=-1, dtype=int)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return peaks, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "302428e2ecb3ece3f0bb2f847e95d683",
     "grade": false,
     "grade_id": "cell-6f0f1198db2abe3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now run the code to check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6e25377798d734c3f65ee1da374f880",
     "grade": false,
     "grade_id": "cell-3f84dad89cc61285",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(f'gaussian_mixture_samples_3d.csv', delimiter=',')\n",
    "radii = [1, 1.25, 2, 8]\n",
    "fig, axes = plt.subplots(\n",
    "    1, len(radii), figsize=(15,4), subplot_kw={'projection': '3d'})\n",
    "\n",
    "for radius, ax in zip(radii, axes): \n",
    "    start_time = time.time()\n",
    "    peaks, labels = mean_shift_opt(data, radius)\n",
    "    plot_3d_clusters(ax, data, labels, peaks)\n",
    "    duration = time.time()-start_time\n",
    "    ax.set_title(\n",
    "        f'Found {len(peaks)} peaks using radius={radius:.2f}\\n'\n",
    "        f'Computation took {duration:.4f} s\\n')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b7480def2711bd7be647e66b7b4ec44",
     "grade": false,
     "grade_id": "cell-bfc4d978cb1ac42b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The **second speedup** is based on a similar principle: Associate points within a distance $\\mathtt{radius}/c$ of the search path with the converged peak ($c$ is some constant value). Use $c = 3$ for this assignment.\n",
    "\n",
    "To realize this speedup, you will need to modify `find_peak` into `find_peak_opt`, which returns two values: `peak` and `is_near_search_path`. The latter should be a Boolean output vector of length $p$ (number of data points) containing `True` for each point that we encountered within a distance $\\mathtt{radius}/c$ on our search path, and `False` for the others. Then use this Boolean vector in a new version of `mean_shift_opt`, called `mean_shift_opt2` to do the label assignments accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99724b141a27434bddc9d23bd2499f8b",
     "grade": true,
     "grade_id": "cell-375afff9bffe7491",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def find_peak_opt(data, query, radius, c=3):\n",
    "    is_near_search_path = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def mean_shift_opt2(data, radius):\n",
    "    labels = np.full(len(data), fill_value=-1, dtype=int)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return peaks, labels\n",
    "\n",
    "data = np.genfromtxt(f'gaussian_mixture_samples_3d.csv', delimiter=',')\n",
    "radii = [1, 1.25, 2, 8]\n",
    "fig, axes = plt.subplots(\n",
    "    1, len(radii), figsize=(15,4), subplot_kw={'projection': '3d'})\n",
    "\n",
    "for radius, ax in zip(radii, axes):\n",
    "    start_time = time.time()\n",
    "    peaks, labels = mean_shift_opt2(data, radius)\n",
    "    plot_3d_clusters(ax, data, labels, peaks)\n",
    "    duration = time.time()-start_time\n",
    "    ax.set_title(f'Found {len(peaks)} peaks using radius={radius:.2f}\\n'\n",
    "                 f'Computation took {duration:.4f} s\\n')\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f432602230c2fdf2b44c1efeecab339b",
     "grade": false,
     "grade_id": "cell-11ab22ff738a62cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which radius gives good results and how would you choose it in general? Can the speedups change the result? If yes, did it get worse in this particular case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58c905848aef1c0dc6c60a540cb0182c",
     "grade": true,
     "grade_id": "cell-1cff4f2c453b1850",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "*POINTS: 3*\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5d81845cd27d06a1c77e02f4eafa92a",
     "grade": false,
     "grade_id": "cell-f976f3d0dbc65434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Image Segmentation by Mean-Shift\n",
    "\n",
    "Now use your mean-shift implementation from above to segment images. Note that although very efficient mean-shift implementations exist, our version here may take several minutes per image. Debug using small images.\n",
    "\n",
    "Implement the function `mean_shift_segment(im, radius)` where `im` is an input RGB image of shape $\\mathtt{height}\\times\\mathtt{width}\\times 3$ and `radius` is the parameter associated with the mean-shift algorithm. The output should be `data`, `peaks`, `labels`, `segmented_image`:\n",
    "\n",
    "* `data` is the array of the data points that you input to the mean-shift algorithm, with $p$ rows and 3 columns.\n",
    "* `peaks` and `labels` are simply the results returned by the `mean_shift` call (without changing them).\n",
    "* The `segmented_image` is constructed by assigning to each pixel the color value of the corresponding cluster's peak.\n",
    "\n",
    "You will need to reshape (`np.reshape`) the image array before feeding it to your mean-shift clustering function. Also, do not forget to convert the pixel values to floating point, using `somearray.astype(float)` and then convert the result back to 8-bit unsigned integers using `somearray.astype(np.uint8)`.\n",
    "\n",
    "Segment the image `terrain_small.png` using `radius` 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb64497d78a44a199d46ff9dc9185131",
     "grade": true,
     "grade_id": "cell-c18d7756305d4bcf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 1\n",
    "\n",
    "def mean_shift_segment(im, radius):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return data, peaks, labels, segmented_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c98f6de08bc398f8ecd0d3046bce41f9",
     "grade": false,
     "grade_id": "cell-bf935cc3dcdc173f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_label_colormap():\n",
    "    \"\"\"Create a color map for visualizing the labels themselves,\n",
    "    such that the segment boundaries become more visible, unlike\n",
    "    in the visualization using the cluster peak colors.\n",
    "    \"\"\"\n",
    "    import matplotlib.colors\n",
    "    rng = np.random.RandomState(2)\n",
    "    values = np.linspace(0, 1, 20)\n",
    "    colors = plt.cm.get_cmap('hsv')(values)\n",
    "    rng.shuffle(colors)\n",
    "    return matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "label_cmap = make_label_colormap()\n",
    "\n",
    "im = imageio.imread('terrain_small.png')\n",
    "start_time = time.time()\n",
    "data, peaks, labels, segmented_im = mean_shift_segment(im, radius=15)\n",
    "duration= time.time()-start_time\n",
    "print(f'Took {duration:.2f} s')\n",
    "\n",
    "fig = plt.figure(figsize=(9.5,8))\n",
    "ax = fig.add_subplot(2, 2, 1)\n",
    "ax.set_title('Original Image')\n",
    "ax.imshow(im)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 2)\n",
    "ax.set_title('Segmented')\n",
    "ax.imshow(segmented_im)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 3)\n",
    "ax.set_title('Labels')\n",
    "ax.imshow(labels.reshape(im.shape[:2]), cmap=label_cmap)\n",
    "\n",
    "ax = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "ax.set_title(f'RGB space')\n",
    "plot_3d_clusters(ax, data, labels, peaks, colors='rgb', axis_names='RGB')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "079ae318f4e812b73c3637d66a43edea",
     "grade": false,
     "grade_id": "cell-c6d1053f704814e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Segmentation in LUV color space\n",
    "Note that mean-shift uses the Euclidean distance metric. Unfortunately, the Euclidean distance in RGB color space does not correlate well to color difference as perceived by people. For example in the green portion of RGB space, large distances are perceived as the roughly same color, whereas in the blue part a small RGB-distance may cause a large change in perceived color. For this reason we will now use the non-linear LUV color space, where the Euclidean distance better models the perceived difference in color.\n",
    "\n",
    "In the function `mean_shift_segment_luv(...)` cluster the image data in LUV color space by first converting the RGB color vectors to LUV using OpenCV: `cv2.cvtColor(rgb_image, cv2.COLOR_RGB2LUV)`. Then convert the resulting cluster centers back to RGB using `cv2.cvtColor(luv_image, cv2.COLOR_LUV2RGB)`.\n",
    "\n",
    "If we want to include spatial *position information* in the feature vectors as well, we can make the feature vectors 5 dimensional by specifying in addition to the the L, U, and V values also the x, and y coordinates of each pixel. Write a function `mean_shift_segment_luv_pos(im, radius)` that does this. **Hint:** useful functions are `np.arange`, `np.meshgrid`, `np.concatenate`, `np.expand_dims`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd30145ccb36521346361402d7ede44f",
     "grade": true,
     "grade_id": "cell-d0ae0d08f2d3c2c0",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 2\n",
    "\n",
    "def mean_shift_segment_luv(im, radius):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return data, peaks, labels, segmented_im\n",
    "    \n",
    "def mean_shift_segment_luv_pos(im, radius, pos_factor=1):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return data, peaks, labels, segmented_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26a5ffb2d639d072925cf01846453337",
     "grade": false,
     "grade_id": "cell-c36f293ca4381d89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "im = imageio.imread('terrain_small.png')\n",
    "data, peaks, labels, segmented_im = mean_shift_segment_luv(im, radius=10)\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "ax.set_title('Segmented (LUV)')\n",
    "ax.imshow(segmented_im)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "ax.set_title('Labels (LUV)')\n",
    "ax.imshow(labels.reshape(im.shape[:2]), cmap=label_cmap)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 3, projection='3d')\n",
    "ax.set_title(f'LUV space')\n",
    "plot_3d_clusters(ax, data, labels, peaks, colors='luv', axis_names='LUV')\n",
    "\n",
    "data, peaks, labels, segmented_im = mean_shift_segment_luv_pos(im, radius=20)\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "ax.set_title('Segmented (LUV+pos)')\n",
    "ax.imshow(segmented_im)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "ax.set_title('Labels (LUV+pos)')\n",
    "ax.imshow(labels.reshape(im.shape[:2]), cmap=label_cmap)\n",
    "\n",
    "ax = fig.add_subplot(2, 3, 6, projection='3d')\n",
    "ax.set_title(f'VXY space')\n",
    "plot_3d_clusters(\n",
    "    ax, data[:, 2:], labels, peaks[:, 2:], \n",
    "    peak_colors=peaks[:, :3], colors='luv', axis_names='VXY')\n",
    "ax.invert_zaxis()\n",
    "ax.view_init(azim=20, elev=15)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "260d4e143c21d9c632dbe41eca330261",
     "grade": false,
     "grade_id": "cell-e1dd44bea559c872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Experiment with the parameters\n",
    "\n",
    "How does the `radius` and the choice of the feature vector affect the resulting segmentations? What effect does adding position information have? Can you suggest any extensions that might avoid many of the situations where single regions are over-segmented into multiple regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ace93034663e4f146906ec44afaf6ddc",
     "grade": true,
     "grade_id": "cell-427095855283067d",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "*POINTS: 3*\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "202784eca576ea04c642d7faa8fc042a",
     "grade": false,
     "grade_id": "cell-fad133b860cbab2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "radii = [5, 10, 20]\n",
    "fig, axes = plt.subplots(len(radii), 3, figsize=(15, 15))\n",
    "for radius, ax in zip(radii, axes):\n",
    "    segmented_im = mean_shift_segment(im, radius)[-1]\n",
    "    ax[0].imshow(segmented_im)\n",
    "    ax[0].set_title(f'Radius {radius} RGB')\n",
    "    \n",
    "    segmented_im = mean_shift_segment_luv(im, radius)[-1]\n",
    "    ax[1].imshow(segmented_im)\n",
    "    ax[1].set_title(f'Radius {radius} LUV')\n",
    "\n",
    "    segmented_im = mean_shift_segment_luv_pos(im, radius)[-1]\n",
    "    ax[2].imshow(segmented_im)\n",
    "    ax[2].set_title(f'Radius {radius} LUV+pos')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2648ab071d314342ed57d915b7b7ef4f",
     "grade": false,
     "grade_id": "cell-e2340385d55e782b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [BONUS] Test it on a larger image\n",
    "\n",
    "Run your algorithm on at least one larger (approx. 300x200) test image using your own choice of `radius` and feature vector definition. One source for possible test images is the dataset of images available at http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/. You can also try the example images included in the scikit-image library, e.g. `import skimage.data; im = skimage.data.astronaut()`. Or any image from anywhere.\n",
    "\n",
    "Processing can take several minutes for larger images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb49143ed22f3716825abe4909769c1",
     "grade": true,
     "grade_id": "cell-22b5011e13b8557a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 0\n",
    "\n",
    "import skimage.data\n",
    "im = skimage.data.astronaut()\n",
    "im = cv2.resize(im, (256,256))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].set_title('Original image')\n",
    "axes[0].imshow(im)\n",
    "axes[1].set_title('Segmented image')\n",
    "axes[1].imshow(segmented_im)\n",
    "axes[2].set_title('Labels')\n",
    "axes[2].imshow(labels.reshape(im.shape[:2]), cmap=label_cmap)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e10bb38c5e57da4d12b3b993bd958954",
     "grade": false,
     "grade_id": "cell-8c943ebd6dc04afb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [BONUS++] Efficient Implementation\n",
    "\n",
    "Mean-shift is highly parallelizable and GPU-based implementations can be many times faster for such workloads.\n",
    "If you already know TensorFlow or CUDA, you can try implementing mean-shift for the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a587c9c16887a2e2f1a23a04d9a2355e",
     "grade": true,
     "grade_id": "cell-684ee995b5053e86",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
